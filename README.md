# LLM (Repositorio en construcci√≥n ‚õèÔ∏èüõ†Ô∏èüî®)
Este repositorio contendr√° los recursos que me sirvieron para aprender sobre LLM's

## Cursos

| Cursos | Link |
|:-|:-:|
| Stanford Lecture - CS324 | https://stanford-cs324.github.io/winter2022/lectures/ |
|  MIT - TinyML and Efficient Deep Learning Computing |  https://hanlab.mit.edu/courses/2023-fall-65940 |
|  Coursera - Generative AI with Large Language Models* |  https://www.coursera.org/learn/generative-ai-with-llms |
|  HuggingFace - A little guide to building Large Language Models in 2024  |  https://youtu.be/2-SPH9hIKT8?si=7wPqBf8t20aln0G7   |
|                      |            |


* `*Curso de pago` 

## Andrej Karpathy 

| T√≠tulos | Links |
|:-:|:-:|
| Let's build GPT: from scratch, in code, spelled out | https://www.youtube.com/watch?v=kCc8FmEb1nY&t=1803s |
| State of GPT | https://www.youtube.com/watch?v=bZQun8Y4L2A |
| [1hr Talk] Intro to Large Language Models | https://www.youtube.com/watch?v=zjkBMFhNj_g&t=2101s |
| Let's build the GPT Tokenizer | https://youtu.be/zduSFxRajkE?si=63aOezV4VH_G5IcU |

## YouTube Channels

| Canales de YouTube | Links | Comentarios |
|:-:|:-:|-|
|  code_your_own_AI  | https://www.youtube.com/@code4AI   | Este canal tiene demasiado contenido hablando sobre los LLM, enfoques, t√©cnicas, etc. Recomendado en un üíØüìà |

## Conferencias de los Art√≠culos

Conferencias de algunos papers que he ido encontrando üëåüèº.

| Conferencias de los Papers | Links | Art√≠culos | GitHub | HuggingFace Blog |
|:-:|:-:|:-:|:-:|:-:|
|  QLoRA: Efficient Finetuning of Quantized LLMs (Tim Dettmers)  |  https://youtu.be/fQirE9N5q_Y?si=ALeiLxiQpb3sdkbL  |  [![arxiv paper](https://img.shields.io/badge/arXiv-Paper-red)](https://arxiv.org/abs/2305.14314)  | https://github.com/artidoro/qlora |  [![hfpaper](https://img.shields.io/badge/ü§óHugginngFace-Blog-yellow)](https://huggingface.co/blog/4bit-transformers-bitsandbytes)  |
| 8-bit Methods for Efficient Deep Learning with Tim Dettmers | https://youtu.be/jyOqtw4ry2w?si=Bwm3emBeMnzwln0Y |  |   |   |

## Cursos de DeepLearningAI (Short Courses)

Para mi los cursos de la plataforma deeplearningai no son muy buenos, pero los recomiendo debido a que puedes ver los v√≠deos y ejecutar los c√≥digos. Esto permite de alg√∫n modo a darte una idea de c√≥mo funcionan las cosas.

| Cursos | Link |
|:-|:-:|
| Finetuning Large Language Models | https://www.deeplearning.ai/short-courses/finetuning-large-language-models/ |
| Reinforcement Learning from Human Feedback | https://www.deeplearning.ai/short-courses/reinforcement-learning-from-human-feedback/ |

## Transformers

A continuaci√≥n, dejar√© links de v√≠deos, blogs, etc acerca del transformer para aprenderlo en detalle ü§Øü§Øüí•üí•

|  |  |
|:-:|:-:|
| Harvard NLP - The Annotated Transformer (Nuevo usando PyTorch)|  https://nlp.seas.harvard.edu/annotated-transformer/  |
| Harvard NLP - The Annotated Transformer (Old)   | https://nlp.seas.harvard.edu/2018/04/03/attention.html |

## Art√≠culos 

| Papers | Link |
|:-|:-:|
| Transformer | [![arxiv paper](https://img.shields.io/badge/arXiv-Paper-red)](https://arxiv.org/abs/1706.03762) |
|  Decoder-Only |   |
| GPT |   |
| GPT-2 |  |
| GPT-3 |  |
|    |     |
